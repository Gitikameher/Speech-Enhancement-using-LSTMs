{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "gpu_options = tf.GPUOptions(allow_growth = True)\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_file = 120\n",
    "\n",
    "max_length = 200\n",
    "\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBM(S, N):\n",
    "    M = []\n",
    "    \n",
    "    for i in range(len(S)):\n",
    "        m_ibm = 1 * (S[i] > N[i])\n",
    "        M.append(m_ibm)\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadfile(path,stri, flag = 1):\n",
    "    list_tr = []\n",
    "    list_stft = []\n",
    "    list_stft_abs = []\n",
    "    list_length = []\n",
    "    \n",
    "    for i in range(n_file):\n",
    "        s, sr = librosa.load(path + 'ratio_'+str(i+1) + '_'+ stri+'.wav', sr = None)\n",
    "        if (flag == 1):\n",
    "            list_tr.append(s)\n",
    "        \n",
    "        #Calculating STFT\n",
    "        stft = librosa.stft(s, n_fft= 1024, hop_length= 512)\n",
    "        \n",
    "        stft_len = stft.shape[1]\n",
    "        \n",
    "        #Appending STFT to list\n",
    "        if (flag == 1):\n",
    "            list_stft.append(stft)\n",
    "        \n",
    "        #Calculating Absolute of STFT\n",
    "        stft_abs = np.abs(stft)\n",
    "        \n",
    "        #Padding zeros to make length 300\n",
    "        stft_abs = np.pad(stft_abs, ((0,0),(0, max_length-stft_len)), 'constant')\n",
    "        \n",
    "        #Appending abs to list\n",
    "        list_stft_abs.append(stft_abs.T)\n",
    "        \n",
    "        #Appending time-length of STFT to list\n",
    "        list_length.append(stft_len)\n",
    "        \n",
    "    return list_tr, list_stft, list_stft_abs, list_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs, S, S_abs, S_len = loadfile(\"clean/\",\"clean\")\n",
    "trx, X, X_abs, X_len = loadfile(\"noisy/\",\"mixture\")\n",
    "tri, I , I_abs, I_len= loadfile(\"IBM/\",\"ideal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [10, None, 513])\n",
    "y_ = tf.placeholder(tf.float32, [10, None, 513])\n",
    "\n",
    "hidden_units = 256\n",
    "out_weights = tf.Variable(tf.random_normal([hidden_units, 513], stddev=2/(hidden_units+513), mean=0)) # xavier init\n",
    "out_bias = tf.Variable(tf.zeros([513]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cell = tf.nn.rnn_cell.LSTMCell(hidden_units, initializer=tf.contrib.layers.xavier_initializer())\n",
    "outputs, _ = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.expand_dims(tf.ones([10, 1]), 1) * out_weights\n",
    "\n",
    "y = tf.nn.sigmoid(tf.matmul(outputs, weights) + out_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.reduce_mean(tf.losses.mean_squared_error(y_, y))\n",
    "train_step = tf.train.AdamOptimizer().minimize(mse) # adam optimizer with default learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() \n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 \tcost=0.244389131\n",
      "Epoch: 02 \tcost=0.232434666\n",
      "Epoch: 03 \tcost=0.229284970\n",
      "Epoch: 04 \tcost=0.226815259\n",
      "Epoch: 05 \tcost=0.225271697\n",
      "Epoch: 06 \tcost=0.224424066\n",
      "Epoch: 07 \tcost=0.223996287\n",
      "Epoch: 08 \tcost=0.223718130\n",
      "Epoch: 09 \tcost=0.223523233\n",
      "Epoch: 10 \tcost=0.223368681\n",
      "Epoch: 11 \tcost=0.223229909\n",
      "Epoch: 12 \tcost=0.223102104\n",
      "Epoch: 13 \tcost=0.222995716\n",
      "Epoch: 14 \tcost=0.222894757\n",
      "Epoch: 15 \tcost=0.222793529\n",
      "Epoch: 16 \tcost=0.222701914\n",
      "Epoch: 17 \tcost=0.222619606\n",
      "Epoch: 18 \tcost=0.222541101\n",
      "Epoch: 19 \tcost=0.222463336\n",
      "Epoch: 20 \tcost=0.222390724\n",
      "Epoch: 21 \tcost=0.222333739\n",
      "Epoch: 22 \tcost=0.222270543\n",
      "Epoch: 23 \tcost=0.222207232\n",
      "Epoch: 24 \tcost=0.222144685\n",
      "Epoch: 25 \tcost=0.222069002\n",
      "Epoch: 26 \tcost=0.222019869\n",
      "Epoch: 27 \tcost=0.221962179\n",
      "Epoch: 28 \tcost=0.221910851\n",
      "Epoch: 29 \tcost=0.221867323\n",
      "Epoch: 30 \tcost=0.221808627\n",
      "Epoch: 31 \tcost=0.221778184\n",
      "Epoch: 32 \tcost=0.221756242\n",
      "Epoch: 33 \tcost=0.221769155\n",
      "Epoch: 34 \tcost=0.221707160\n",
      "Epoch: 35 \tcost=0.221624671\n",
      "Epoch: 36 \tcost=0.221589799\n",
      "Epoch: 37 \tcost=0.221522746\n",
      "Epoch: 38 \tcost=0.221483670\n",
      "Epoch: 39 \tcost=0.221432803\n",
      "Epoch: 40 \tcost=0.221394466\n",
      "Epoch: 41 \tcost=0.221361802\n",
      "Epoch: 42 \tcost=0.221307184\n",
      "Epoch: 43 \tcost=0.221299995\n",
      "Epoch: 44 \tcost=0.221295263\n",
      "Epoch: 45 \tcost=0.221284291\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b15ba23f9bcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_abs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mI_abs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%02d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\tcost={:.9f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(0, 120, 10):\n",
    "        batch_x = X_abs[i:i+10] \n",
    "        batch_y = I_abs[i:i+10]\n",
    "        _, cost = sess.run([train_step, mse], feed_dict={x: batch_x, y_: batch_y})\n",
    "        avg_cost += cost/120\n",
    "    print(\"Epoch:\", '%02d'%(epoch+1), \"\\tcost={:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model.ckpt\"\n",
    "# saving the model\n",
    "save_path = saver.save(sess, model_path)\n",
    "# restore trained model to use for validation\n",
    "saver.restore(sess, model_path)\n",
    "# load pickled time domain S_v: clean signals from validation set\n",
    "\n",
    "with open('data/validation_clean.pkl', 'rb') as f:\n",
    "    s = pickle.load(f)\n",
    "# loading picked validation set files X_v, S_v, N_v in stft domain\n",
    "\n",
    "with open('data/validation.pkl', 'rb') as f:\n",
    "    X_v, S_v, N_v = pickle.load(f)\n",
    "\n",
    "# taking magnitude and transpose\n",
    "\n",
    "X_v_mod = [np.abs(signal).T for signal in X_v]\n",
    "S_v_mod = [np.abs(signal).T for signal in S_v]\n",
    "N_v_mod = [np.abs(signal).T for signal in N_v]\n",
    "X_v_T = [signal.T for signal in X_v]\n",
    "\n",
    "M_v = []\n",
    "for i in range(1200):\n",
    "    M_v.append(np.greater(S_v_mod[i], N_v_mod[i]).astype(int))\n",
    "\n",
    "# checking validation loss and calculating snr\n",
    "\n",
    "avg_cost = 0\n",
    "snr = []\n",
    "\n",
    "for i in range(0, 1200, 10):\n",
    "    batch_x = X_v_mod[i:i+10] \n",
    "    batch_y = M_v[i:i+10]\n",
    "\n",
    "    cost, M_hat = sess.run([mse, y], feed_dict={x: batch_x, y_: batch_y})\n",
    "    \n",
    "    avg_cost += cost/120\n",
    "    \n",
    "    batch_x_complex = X_v_T[i:i+10]\n",
    "    batch_s = s[i:i+10]\n",
    "    for j in range(10):\n",
    "        S_hat = np.multiply(M_hat[j], batch_x_complex[j])\n",
    "        s_hat = librosa.istft(S_hat.T, win_length=1024, hop_length=512)\n",
    "        \n",
    "        t = min(len(s_hat), len(batch_s[j]))\n",
    "        snr.append(10*np.log10((np.sum(np.square(batch_s[j][:t])))/np.sum(np.square(batch_s[j][:t]-s_hat[:t]))))\n",
    "\n",
    "print(\"Validation loss = {:.9f}\".format(avg_cost))\n",
    "print(\"SNR = \", sum(snr)/1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames of test files (400 test files)\n",
    "te_filenames = ['tex{}.wav'.format(id) for id in ids[:400]]\n",
    "\n",
    "# load pickled test files X_te in stft domain\n",
    "\n",
    "with open('data/test.pkl', 'rb') as f:\n",
    "    X_te, srs = pickle.load(f)\n",
    "    \n",
    "\n",
    "# taking magnitude and transpose\n",
    "\n",
    "X_te_mod = [np.abs(signal).T for signal in X_te]\n",
    "X_te_T = [signal.T for signal in X_te]\n",
    "\n",
    "# reconstructing test signals\n",
    "\n",
    "for i in range(0, 400, 10):\n",
    "    batch_x = X_te_mod[i:i+10] \n",
    "    M_hat = sess.run(y, feed_dict={x: batch_x})\n",
    "    \n",
    "    batch_x_complex = X_te_T[i:i+10]\n",
    "    batch_filenames = te_filenames[i:i+10]\n",
    "    batch_sr = srs[i:i+10]\n",
    "    for j in range(10):\n",
    "        S_hat = np.multiply(M_hat[j], batch_x_complex[j])\n",
    "        s_hat = librosa.istft(S_hat.T, win_length=1024, hop_length=512)\n",
    "        librosa.output.write_wav('recons'+batch_filenames[j][-11:], s_hat, srs[j])\n",
    "        \n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
